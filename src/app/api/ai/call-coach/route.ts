/**
 * REAL-TIME AI CALL COACHING ENDPOINT
 *
 * Ultra-optimized for speed:
 * - Streaming responses (300-500ms TTFT)
 * - Prompt caching (40% latency reduction)
 * - Token limits for faster generation
 * - Lead context pre-loading
 *
 * Target: <500ms from request to first token
 */

import { NextRequest, NextResponse } from 'next/server';
import Anthropic from '@anthropic-ai/sdk';

const anthropic = new Anthropic({
  apiKey: process.env.ANTHROPIC_API_KEY,
});

export const runtime = 'edge'; // Edge runtime for lower latency

export async function POST(req: NextRequest) {
  try {
    const { transcript, leadContext, conversationHistory } = await req.json();

    if (!transcript) {
      return NextResponse.json(
        { error: 'Transcript required' },
        { status: 400 }
      );
    }

    // Build ultra-concise coaching prompt (less tokens = faster)
    const systemPrompt = buildSystemPrompt(leadContext);
    const userPrompt = buildUserPrompt(transcript, conversationHistory);

    // Stream from Claude with optimizations
    const stream = await anthropic.messages.stream({
      model: 'claude-sonnet-4-5-20250929',
      max_tokens: 100, // SHORT responses = faster generation
      temperature: 0.7,
      system: [
        {
          type: 'text',
          text: systemPrompt,
          cache_control: { type: 'ephemeral' }, // Cache system prompt
        },
      ],
      messages: [
        {
          role: 'user',
          content: userPrompt,
        },
      ],
    });

    // Create ReadableStream for client
    const encoder = new TextEncoder();
    const readableStream = new ReadableStream({
      async start(controller) {
        try {
          for await (const chunk of stream) {
            if (
              chunk.type === 'content_block_delta' &&
              chunk.delta.type === 'text_delta'
            ) {
              const text = chunk.delta.text;
              controller.enqueue(encoder.encode(text));
            }
          }
          controller.close();
        } catch (error) {
          controller.error(error);
        }
      },
    });

    return new Response(readableStream, {
      headers: {
        'Content-Type': 'text/plain; charset=utf-8',
        'Transfer-Encoding': 'chunked',
        'Cache-Control': 'no-cache',
      },
    });
  } catch (error) {
    console.error('[AI Call Coach] Error:', error);
    return NextResponse.json(
      { error: 'Failed to generate coaching suggestion' },
      { status: 500 }
    );
  }
}

/**
 * Build system prompt with lead context (cached for performance)
 */
function buildSystemPrompt(leadContext?: any): string {
  const basePrompt = `You are an expert B2B sales coach providing INSTANT, CONCISE suggestions during live sales calls.

RULES:
- Respond in 15 words or less
- Be direct and actionable
- Focus on next thing to say
- Use casual, natural language
- No fluff or explanations`;

  if (!leadContext) return basePrompt;

  return `${basePrompt}

LEAD CONTEXT:
Name: ${leadContext.name}
Business: ${leadContext.business_type || 'Local business'}
Rating: ${leadContext.rating || 'N/A'}â­ (${leadContext.user_ratings_total || 0} reviews)
Score: ${leadContext.score || 'N/A'}/100
Phone: ${leadContext.phone || 'N/A'}
Website: ${leadContext.website ? 'Yes' : 'No'}

KEY INSIGHTS:
${generateKeyInsights(leadContext)}`;
}

/**
 * Generate key insights from lead data
 */
function generateKeyInsights(lead: any): string {
  const insights: string[] = [];

  if (lead.score && lead.score >= 80) {
    insights.push('- HIGH QUALITY LEAD - Strong fit');
  }

  if (lead.rating && lead.rating >= 4.5) {
    insights.push('- Excellent reputation - Use as trust signal');
  }

  if (lead.user_ratings_total && lead.user_ratings_total > 100) {
    insights.push('- Established business - Has customer base');
  }

  if (!lead.website) {
    insights.push('- NO WEBSITE - Major opportunity for digital presence');
  }

  if (lead.business_status === 'OPERATIONAL') {
    insights.push('- Currently operating - Active business');
  }

  return insights.length > 0
    ? insights.join('\n')
    : '- Standard local business prospect';
}

/**
 * Build user prompt with conversation context
 */
function buildUserPrompt(
  transcript: string,
  conversationHistory?: Array<{ speaker: string; text: string }>
): string {
  let prompt = '';

  // Add recent conversation history (last 3 exchanges max)
  if (conversationHistory && conversationHistory.length > 0) {
    const recentHistory = conversationHistory.slice(-3);
    prompt += 'RECENT CONVERSATION:\n';
    recentHistory.forEach((msg) => {
      prompt += `${msg.speaker}: "${msg.text}"\n`;
    });
    prompt += '\n';
  }

  // Add current transcript
  prompt += `PROSPECT JUST SAID: "${transcript}"\n\n`;
  prompt += `YOUR COACHING (15 words max):`;

  return prompt;
}

/**
 * Health check endpoint
 */
export async function GET() {
  return NextResponse.json({
    status: 'healthy',
    service: 'AI Call Coach',
    model: 'claude-sonnet-4-5-20250929',
    features: ['streaming', 'prompt-caching', 'lead-context'],
  });
}
